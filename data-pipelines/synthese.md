# Mise en application des _data pipelines_ dans une plateforme analytique _Big data_ de valorisation de donn√©es spatiales d√©di√©e √† l‚Äôaide √† la d√©cision en mati√®re de v√©g√©talisation

| FRANCE 2030 | Banque des Territoires, Groupe Caisse des D√©p√¥ts | IA.rbre | LIRIS |
| --- | --- | --- | --- |
| ![Logo FRANCE 2030](../assets/logos/logo-france-2030.svg) | ![Logo Banque des Territoires, Groupe Caisse des D√©p√¥ts](../assets/logos/logo-banque-des-territoires.svg) | ![Logo IA.rbre](../assets/logos/logo-iarbre-with-picto.svg) | ![Logo LIRIS](../assets/logos/logo-liris.svg) |

---

- Projet
  - **Projet** : IA.rbre
  - **Porteur du projet** : TelesCoop
  - **Membres du consortium** :
    - M√©tropole de Lyon
    - TelesCoop
    - Universit√© Lumi√®re Lyon 2 (agissant pour le compte du LIRIS)
  - **Dur√©e** : 36 mois (2025 √† 2028)
  - **D√©but** : 2025-03-10
  - **Appel √† projet** : D√©monstrateurs d‚ÄôIA frugale au service de la transition √©cologique de territoires (DIAT)
  - **Plan** : FRANCE 2030
  - **Financement** : Banque des Territoires, Groupe Caisse des D√©p√¥ts

---

- Document
  - **Auteur(s)** :
    - Mika Inisan (LIRIS, mika.inisan _at_ liris.cnrs.fr)
  - **Relecteur(s)** :
    - Arthur Villarroya-Palau (LIRIS, arthur.villarroya-palau _at_ liris.cnrs.fr)
    - John Samuel (LIRIS, john.samuel _at_ liris.cnrs.fr)
    - Gilles Gesqu√®re (LIRIS, gilles.gesquiere _at_ liris.cnrs.fr)
  - **Date de cr√©ation** : 2025-05-20
  - **Date de derni√®re mise √† jour** : 2025-11-13
  - **Version** : 1.0.2
  - **Classification documentaire** : Public
  - **Langue** : Fran√ßais
  - **Statut** : Final
  - **Licence** : [LICENSE.md](./LICENSE.md) (inclut les conditions relatives aux images)

---

- 1. Avant-propos
- 2. Introduction
- 3. Pr√©sentation de IA.rbre
  - 3.1 Contexte et objectifs g√©n√©raux
  - 3.2 Objectifs techniques
- 4. √âbauche d'une _data pipeline_
  - 4.1. Profilage (semi-automatisable)
  - 4.2. Acquisition et ingestion (automatisable)
  - 4.3. Pr√©traitement et int√©gration (semi-automatisable)
  - 4.4. Analyse et mod√©lisation (automatisable)
  - 4.5. Restitution et visualisation
  - 4.6. Gouvernance, qualit√© et reproductibilit√©
- 5. R√©f√©rences
- Annexe A. Fondations des cha√Ænes de traitement de donn√©es
- Annexe B. Types de traitement de donn√©es, syst√®mes de stockage et de gestion de donn√©es

## 1. Avant-propos

Ce document est le fruit d'une premi√®re it√©ration, volontairement limit√©e √† une dur√©e de 20 jours ouvr√©s, d'un travail de recherche sur les cha√Ænes de traitement de donn√©es. Il vise √† fournir une vue d‚Äôensemble du sujet et √† servir de point de d√©part aux √©changes avec les parties prenantes. Un approfondissement cibl√© pourra ensuite √™tre men√© dans une seconde it√©ration (e.g., proposition d'une architecture compl√®te, _proof of concept_ pour le projet IA.rbre), en fonction des retours recueillis et des besoins effectifs identifi√©s.

Voici quelques limites de ce document par rapport √† un article scientifique exemplaire :
- Appui non exclusivement sur la litt√©rature scientifique avec de la litt√©rature grise (blogs, magazines, sites Web‚Ä¶).
- √âtat de l'art ni exhaustif ni syst√©matique, induisant un manque de repr√©sentativit√© avec la diversit√© et la qualit√© des r√©f√©rences.

## 2. Introduction

La complexification progressive de la gestion, de l‚Äôanalyse et de la valorisation des donn√©es, coupl√©e √† l'explosion du volume de donn√©es disponibles et exploitables, issues d‚Äôune diversit√© croissante de sources et marqu√©es par une grande h√©t√©rog√©n√©it√©, a ouvert l‚Äô√®re du _Big data_. Ce ph√©nom√®ne est souvent r√©sum√© par les ¬´ 5 V ¬ª (volume, v√©locit√©, vari√©t√©, v√©racit√© et valeur) auxquels il est possible d'ajouter d'autres V comme variabilit√© [77].

Bien que des avanc√©es majeures aient √©t√© r√©alis√©es, certains d√©fis persistent. Entre autres :
- Disponibilit√© et accessibilit√© des donn√©es de sources vari√©es, dont les services et l'infrastructure sous-jacente.
- Compl√©tude des donn√©es (toutes les donn√©es sont accessibles ainsi que leurs d√©pendances).
- Qualit√© des donn√©es initiales et conservation de la qualit√© le long du cycle de vie.
- Int√©gration de donn√©es aux formats h√©t√©rog√®nes de sources diff√©rentes et leur gestion dans tous les traitements.
- Performance, scalabilit√© adapt√©e au volume de donn√©es.
- Flexibilit√©, adaptabilit√© et √©volution des traitements au format de donn√©es et aux besoins m√©tiers.
- Standardisation, uniformisation, normalisation, structuration des traitements.
- Valorisation des donn√©es, r√©utilisabilit√©, reproductibilit√©, r√©plicabilit√©.
- Complexit√©, maintenance, d√©pannage, d√©bogage, tol√©rance √† l'erreur, fiabilit√© et co√ªts √©lev√©s associ√©s.
- Erreur humaine, t√¢ches manuelles fastidieuses et co√ªts √©lev√©s associ√©s.
- Conformit√© l√©gale (RGPD‚Ä¶) dont la tra√ßabilit√©, gestion du risque et s√©curit√©.
- Interdisciplinarit√©.
- Diss√©mination, diffusion, partage, compr√©hension.

Les cha√Ænes de traitement de donn√©es, ou _data pipelines_, occupent une place de plus en plus centrale au sein des syst√®mes de gestion de donn√©es contemporains gr√¢ce √† leur r√¥le structurant. Elles permettent d‚Äôautomatiser l‚Äôint√©gration, le nettoyage et la transformation de volumes importants de donn√©es provenant de sources h√©t√©rog√®nes. En rempla√ßant des op√©rations manuelles susceptibles d‚Äôintroduire des erreurs par des processus syst√©matiques et reproductibles, elles favorisent la qualit√© des donn√©es, leur tra√ßabilit√© et leur actualisation r√©guli√®re. Cette approche contribue √† am√©liorer la coh√©rence des syst√®mes d‚Äôinformation, √† r√©duire la fragmentation des donn√©es et √† faciliter un acc√®s en temps r√©el √† l‚Äôinformation, conditions n√©cessaires √† une prise de d√©cision plus fiable et √† une meilleure efficacit√© organisationnelle.

Le projet IA.rbre, plateforme analytique _Big data_ d√©di√©e √† la valorisation de donn√©es g√©ospatiales pour l‚Äôaide √† la d√©cision en mati√®re de v√©g√©talisation urbaine, illustre concr√®tement les d√©fis caract√©ristiques du _Big data_.

Ce document pr√©sente, dans un premier temps, le contexte et les objectifs du projet IA.rbre, puis propose, dans un second temps, une √©bauche de _data pipeline_ con√ßue pour en structurer la r√©ponse, en s‚Äôappuyant sur les fondements issus de la litt√©rature scientifique (Annexes A et B). Il investigue la probl√©matique : comment les _data pipelines_ permettent de r√©pondre √† une partie des d√©fis majeurs de la _data science_ et du _Big data_, tout en fournissant une structure qui facilite la r√©solution des autres ?

## 3. Pr√©sentation de IA.rbre

### 3.1 Contexte et objectifs g√©n√©raux

Le projet IA.rbre est un des 12 laur√©ats de l'appel √† projets d'innovation ¬´ D√©monstrateurs d‚ÄôIA frugale au service de la transition √©cologique des territoires ¬ª (DIAT) lanc√© par la Banque des territoires dans le cadre du plan d'investissement ¬´ France 2030 ¬ª, de la strat√©gie ¬´ Ville durable et b√¢timents innovants ¬ª et de la strat√©gie nationale pour l'intelligence artificielle.

Financ√© sur 36 mois, il consiste au co-d√©veloppement, avec un grand nombre d'acteurs terrains en charge de la gestion du territoire, et selon une d√©marche it√©rative de prise en compte de leurs besoins communs, d'une plateforme Web analytique _Big data_ interservices interop√©rables de donn√©es territoriales en vue de localiser des zones sur lesquelles il est possible de planter des arbres, sur lesquelles il serait optimal de planter, de v√©g√©taliser, de densifier la v√©g√©talisation, et d'aider √† la d√©cision.

Le projet s'inscrit dans la continuit√© de travaux initi√©s par plusieurs des acteurs dont certains du projet comme le projet ¬´ Calque de plantabilit√© ¬ª qui a abouti sur une premi√®re version d'un calque d√©di√© √† la v√©g√©tation haute, qui constitue la base de travail pour IA.rbre.

Un pr√©requis important est l'identification, l'inventaire, la collecte et l'int√©gration des donn√©es (donn√©es de r√©seaux, chantiers, inventaire du v√©g√©tal urbain existant dont le patrimoine v√©g√©tal notamment avec le projet iPAV√â [74], donn√©es d'occupation des sols‚Ä¶) des diff√©rents services publics (comme DataGrandLyon ou IGN) et acteurs priv√©s (e.g., donn√©es issues d'une d√©marche de D√©claration d‚ÄôIntention de Commencement de Travaux (DICT) [75] aupr√®s d'exploitant des r√©seaux locaux comme TCL [76], ENEDIS, SFR‚Ä¶) permettant l'am√©lioration de la connaissance du territoire.

**O√π peut-on planter ?** Gr√¢ce au croisement de ces donn√©es, il est possible d'identifier, de mani√®re pr√©cise et √† grande √©chelle, les zones les plus favorables √† la v√©g√©talisation via le calcul d'une multitude de facteurs de faisabilit√© (ind√©pendants de l'usage) pond√©r√©s (pr√©sence d'un parking, pr√©sence d'un giratoire, pr√©sence d'une voie ferr√©e, pr√©sence d'un r√©seau de gaz‚Ä¶) permettant de g√©n√©rer un calque de plantabilit√© o√π chaque pixel, de r√©solution d√©pendante des donn√©es, est color√© en fonction de la probabilit√© qu'il soit possible d'implanter un arbre ou de la v√©g√©tation √† cet endroit.

**O√π devrions-nous planter ?** L'usage est ensuite pris en compte et les enjeux crois√©s, gr√¢ce √† diff√©rents calques th√©matiques (potentiel de d√©simperm√©abilisation, habitabilit√© incluant les Zones Climatiques Locales et l'√©tude de la vuln√©rabilit√© des populations‚Ä¶) pour permettre la plantation plus efficace avec la maximisation de l'utilisation des services √©cosyst√©miques des arbres (r√©duction de la pollution sonore, qualit√© de l'air dont la s√©questration de particules de CO2, protection solaire et rafra√Æchissement, lutte contre le ruissellement‚Ä¶)

La premi√®re √©tape du projet concerne le territoire et les donn√©es de la M√©tropole de Lyon mais la plateforme doit √™tre r√©plicable sur les autres communes, en fonction des donn√©es disponibles, pour permettre un passage √† l'√©chelle. Cela n√©cessite une grande adaptabilit√© √† ces donn√©es. L'absence des donn√©es peut parfois √™tre palli√©e par la transf√©rabilit√© des mod√®les.

Un regard doit √™tre port√© sur la cybers√©curit√© pour s'assurer de la confidentialit√© des donn√©es sensibles en conformit√© avec le RGPD.

Quelques mots pour caract√©riser le projet : frugal, responsable, donn√©es FAIR, _open data_, _open source_ (code, documentation, m√©thodologie de d√©veloppement logiciel, m√©thodologie de r√©ponse √† des objectifs d'int√©r√™t g√©n√©ral, r√©sultats, choix, limites‚Ä¶), _open innovation_, _open science_, reproductibilit√©, bien commun, souverainet√© europ√©enne (outils, donn√©es, infrastructure, acteurs impliqu√©s‚Ä¶), transparence, explicabilit√©, interpr√©tabilit√©.

### 3.2 Objectifs techniques

IA.rbre vient compl√©menter le calque de plantabilit√© pour pallier ses limites et r√©pondre aux besoins des acteurs m√©tiers. Il a comme objectifs techniques principaux :
- D'ajouter de nouvelles donn√©es (mod√®les, donn√©es territoriales, v√©rit√© terrain, donn√©es issues de mod√®les) qui n‚Äô√©taient pas disponibles, de qualit√© insuffisante, sensibles ou jusqu‚Äôalors inconnues, la g√©n√©ration de nouvelles donn√©es √† partir de celles existantes, l'am√©lioration des donn√©es par croisement pour permettre les objectifs suivants. Cela n√©cessite le d√©veloppement de connecteurs, le contr√¥le de la qualit√©, des heuristiques de r√©conciliation de donn√©es‚Ä¶
- De transformer les donn√©es ing√©r√©es en indices interm√©diaires √† l'√©chelle de la maille.
- De reproduire et am√©liorer la qualit√©, la fiabilit√© et l'explicabilit√© de l'indice de plantabilit√© (e.g, par IA), bas√© sur les indices interm√©diaires, gr√¢ce √† une maille plus fine pour les calculs, la prise en compte de facteurs qui n'avaient pas pu √™tre pris en compte √† cause de l'absence de donn√©es ou de la qualit√©, des indices interm√©diaires et une pond√©ration automatique, via des m√©thodes d'analyse, des facteurs de faisabilit√© et d'usage √† l'√©chelle de la maille, mod√©liser la marge d'erreur.
- D√©velopper un mod√®le des diff√©rentes strates de v√©g√©tation pour la pr√©diction.
- D'√©tendre l'analyse aux enjeux d'usage de la v√©g√©tation (d√©simperm√©abilisation, rafra√Æchissement des villes, Zones Climatiques Locales (ZCL)‚Ä¶) gr√¢ce √† la cr√©ation de calques th√©matiques pouvant √™tre utilis√©s pour croiser les enjeux.
- D'am√©liorer la r√©utilisabilit√©, l'int√©grabilit√©.
- D'am√©liorer la plateforme de visualisation (calques, indices‚Ä¶) et de fournir plusieurs outils d'analyse et d'aide √† la prise de d√©cision (module d'annotation des cartes, changement de la pond√©ration des facteurs‚Ä¶).
- De g√©rer les donn√©es dans le temps pour la reproductibilit√© et pour ensuite fournir un outil d'exploration de sc√©nario et de l'√©volution temporelle des villes.

Pour sous-tendre chacun de ces objectifs, un objectif majeur du projet est la conception d'une _data pipeline_.

## 4. √âbauche d'une _data pipeline_

√âmergentes des besoins, des objectifs, des contraintes et des d√©fis (directement issus des d√©fis du _Big data_ appliqu√© √† la science de l'information g√©ospatiale) du projet, les √©tapes et t√¢ches principales sont identifiables. Voici une premi√®re √©bauche de la _data pipeline_ du projet IA.rbre permettant d'apporter des pistes de r√©flexion et des bribes de solutions. Elle reste non exhaustive et ne pr√©tend pas r√©soudre ou lever l‚Äôensemble des probl√©matiques qui devront √™tre trait√©es pour assurer l‚Äôalignement avec les objectifs du projet et son impl√©mentation. Les pr√©requis comme le profilage sont inclus comme √©tapes de la _data pipeline_ √©tant donn√© que certains aspects sont automatisables.

Les annexes peuvent √™tre consult√©es au besoin : l‚Äôannexe A pour les principes des _data pipelines_, et l‚Äôannexe B pour les types de traitements de donn√©es et les solutions de gestion et de stockage.

### 4.1. Profilage (semi-automatisable)

- Identification, inventaire, documentation et s√©lection des sources de donn√©es et donn√©es candidates (donn√©es territoriales, donn√©es d'entra√Ænements, mod√®les, v√©rit√©s terrain, m√©tadonn√©es) parmi un large √©ventail (donn√©es issues d'une infrastructure de donn√©es spatiales urbaines, bases de donn√©es g√©ospatiales, donn√©es g√©n√©r√©es ponctuellement par un service √† l'issue de la commande d'une √©tude, donn√©es issues d'une d√©marche DICT, donn√©es issues d'autres projets‚Ä¶) et en incluant le niveau de protection des donn√©es.
- V√©rification de l‚Äôaccessibilit√©, de la disponibilit√© et de la p√©rennit√© de chaque source (format, licence, provenance, fr√©quence de mise √† jour‚Ä¶) en lien avec le principe FAIR.
- Analyses pr√©liminaires de la qualit√© et statistique (r√©solution spatiale, pr√©cision g√©om√©trique et topologique, repr√©sentativit√© temporelle, exhaustivit√©, pr√©sence de biais, exactitude, compl√©tude, coh√©rence logique, coh√©rence topologique, coh√©rence interdonn√©es, actualisation, volume, d√©tection de duplications et d'erreurs, fiabilit√©‚Ä¶).
- √âvaluation de la contribution marginale de chaque jeu de donn√©es et de la redondance (e.g., par r√©duction de dimensions, analyses factorielles, tests de redondance).
- S√©lection finale en prenant en compte la substituabilit√© (pr√©voir des alternatives lorsqu‚Äôune donn√©e est manquante ou co√ªteuse √† int√©grer).
- √âlaboration d'une strat√©gie d'ingestion incluant les √©tapes n√©cessitant l'intervention humaine, la gestion des acc√®s.

Points d‚Äôattention :
- Certaines donn√©es sont sensibles, clivantes ou difficiles √† obtenir (r√©seaux enterr√©s, fr√©quentation de rues, donn√©es priv√©es), ces r√©sistances vont au‚Äëdel√† des d√©fis techniques classiques des _data pipelines_.
- Devant la difficult√© d'automatisation de certaines t√¢ches, le recours √† l'humain est n√©cessaire √† cette √©tape.

### 4.2. Acquisition et ingestion (automatisable)

- V√©rification de la disponibilit√© et de l'accessibilit√© des sources de donn√©es, donn√©es et substituts.
- Ingestion, dont stockage, par exemple, dans un _data lake_ (Annexe B, section B.2.3.) ou un _data lakehouse_ (Annexe B, section B.2.4.), avec contr√¥le de versions de donn√©es pour la comparabilit√©, la reproductibilit√© et la sc√©narisation.

Pr√©requis :
- D√©veloppement de connecteurs pour automatiser la collecte, notamment via API, t√©l√©chargement ou import manuel, selon la disponibilit√© des sources.

Points d‚Äôattention :
- La fr√©quence d'actualisation des sources de donn√©es et leur disponibilit√© est h√©t√©rog√®ne. Il est possible de mettre en place des m√©canismes de v√©rification d'actualisation et de disponibilit√© qui red√©clenchent automatiquement une partie de l'ingestion.
- Le volume peut rapidement exploser, une ingestion incr√©mentale (ne r√©cup√©rer que les changements) peut √™tre mise en place.

### 4.3. Pr√©traitement et int√©gration (semi-automatisable)

Il peut y avoir des diff√©rences de types de donn√©es (donn√©es territoriales, donn√©es d'entra√Ænements, mod√®les, v√©rit√©s terrain, m√©tadonn√©es ; imagerie, nuage de points, cartes ; _rasters_, donn√©es vectorielles ; b√¢timents, cours d'eau ; GeoTiff, CityGML‚Ä¶), d'actualisation, temporelles, spatiales comme la r√©solution et le syst√®me de projection, de qualit√© et de pratiques (car obtenu par des m√©thodes diff√©rentes, de disciplines diff√©rentes, servant des objectifs diff√©rents).

Le but de cette √©tape est de r√©concilier les donn√©es territoriales dans un format homog√®ne FAIR permettant la comparabilit√© en r√©solvant les discordances, et, selon l'approche frugale, d'organiser les donn√©es pour maximiser la r√©utilisabilit√© et leur minimalit√©.

Cela inclut : le nettoyage, le d√©doublonnage, la r√©duction de dimensions quand n√©cessaire, l'all√®gement, la factorisation, le reformatage, la normalisation, la correction d'erreurs, la compl√©tion et l'am√©lioration.

√Ä la mani√®re de l'architecture m√©daillon (Annexe A, section A.5.2.6.), si l'ingestion a √©t√© faite dans un _data lake_ (Annexe B, section B.2.3.), le r√©sultat peut √™tre stock√© dans un _data warehouse_ (Annexe B, section B.2.1.). Si l'ingestion a √©t√© faite dans un _data lakehouse_, le r√©sultat est compos√© de vues sur ce m√™me _data lakehouse_ (Annexe B, section B.2.4.).

Pr√©requis :
- D√©veloppement d'adaptateurs, qui peuvent √™tre bas√©s sur des heuristiques, pour harmoniser les donn√©es dans un format comparable.
- Ici encore, devant la difficult√© d'automatisation de certaines t√¢ches, le recours √† l'humain peut √™tre n√©cessaire.

Point d‚Äôattention :
- La r√©conciliation multi-sources g√©ospatiales est un d√©fi majeur et peut √™tre l'√©tape la plus fastidieuse.

### 4.4. Analyse et mod√©lisation (automatisable)

Les donn√©es pr√©trait√©es alimentent diff√©rentes briques analytiques :
- Calcul des facteurs de faisabilit√© (pr√©sence d‚Äôun r√©seau, type de sol, contrainte urbaine) et d'autres facteurs, notamment d'usage, (identification des strates, pr√©diction de la possibilit√© de densification des pieds d'arbre, potentiel de d√©simperm√©abilisation des sols, estimation du niveau d'anthropisation des sols, pr√©dire les zones climatiques locales ZCL permettant de pr√©dire les zones o√π le potentiel de rafra√Æchissement urbain est le plus grand, mod√®le d'habitabilit√©) simples, avec heuristiques (normes pour les r√©seaux enterr√©s, pour les r√©seaux v√©g√©taux‚Ä¶) sur les donn√©es initiales, ou n√©cessitant du _machine learning_, y compris l'entra√Ænement de mod√®les (uniquement si aucune autre m√©thode ou r√©sultats n'existent), avec possibilit√© de substitution de donn√©es en cas d'indisponibilit√©. Nous pouvons envisager trois chemins pour la _data pipeline_, √† l‚Äôimage de la Figure 4 de l'annexe A :
  - Entra√Æner les mod√®les sur des donn√©es pr√©trait√©es, puis stocker les _artifacts_ afin de pr√©dire les facteurs √† partir de ceux-ci. Cette approche s‚Äôapplique notamment lorsque les donn√©es sont tr√®s pr√©cises et abondantes, comme c‚Äôest le cas pour la M√©tropole de Lyon.
  - R√©utiliser directement des mod√®les d√©j√† entra√Æn√©s sur une autre ville pour effectuer des pr√©dictions. Cette strat√©gie convient lorsque les donn√©es locales sont incompl√®tes, de faible qualit√© ou insuffisantes pour concevoir un mod√®le performant, situation typique des m√©tropoles plus petites ou moins avanc√©es en mati√®re de gouvernance de la donn√©e.
  - Surentra√Æner des mod√®les existants sur les donn√©es locales, puis effectuer la pr√©diction. Cette option correspond √† un cas interm√©diaire entre les deux pr√©c√©dents.
- Production d‚Äôindices interm√©diaires (e.g. indice d‚Äôimperm√©abilisation, indice d‚Äôanthropisation).
- G√©n√©ration de calques th√©matiques croisant faisabilit√© et usages (d√©simperm√©abilisation, Zones Climatiques Locales, habitabilit√©).
- G√©n√©ration de donn√©es et mod√®les interm√©diaires, via les donn√©es initiales, et finaux, via les donn√©es initiales, mod√®les, v√©rit√© terrain et donn√©es interm√©diaires (pr√©diction de plantabilit√©, mod√©lisation des strates v√©g√©tales, am√©lioration de la pond√©ration de facteurs via apprentissage).
- Calcul de l'√©volution des donn√©es pour l'appr√©hension de la transformation des villes dans le temps (√©volution temporelle) et pr√©diction pour la simulation et la sc√©narisation (simuler l'√©volution de la canop√©e sur les Zones Climatiques Locales‚Ä¶).
- Calcul de l'indice de plantabilit√© par pond√©ration des facteurs.
- _A/B testing_.

Nous pouvons imaginer r√©aliser des calculs sur plusieurs donn√©es √† la m√™me temporalit√© ou sur une donn√©e et ses √©volutions (notamment pour l'aspect sc√©narisation du projet).

Les r√©sultats sont stock√©s pour √™tre utilis√©s dans les √©tapes suivantes.

Points d‚Äôattention :
- N√©cessit√© de mesurer la valeur ajout√©e de chacun de ces mod√®les (gain li√© √† l‚Äôint√©gration d‚Äôune donn√©e suppl√©mentaire, niveau d‚Äôincertitude, marge d‚Äôerreur‚Ä¶). Cela demande des protocoles d‚Äô√©valuation sp√©cifiques.
- Possibilit√© de faire de l'apprentissage et de l'am√©lioration continus en d√©clenchant automatiquement cette √©tape apr√®s √©volution des donn√©es initiales.
- La comparabilit√© est fondamentale pour la fiabilit√©, l'explicabilit√©, la transparence, pouvoir suivre l'√©volution de la ville‚Ä¶ Elle est √©galement n√©cessaire pour faire de l'_A/B testing_ et des _benchmarks_ de mod√®les, de m√©thodes de calcul‚Ä¶ Par exemple, un indice de plantabilit√© calcul√© sur des donn√©es √† un instant _t1_ avec _n1_ facteurs n'est pas comparable avec celui calcul√© sur les m√™mes donn√©es √† un instant _t2_ avec _n2_ facteurs. Les performances d'un mod√®le entra√Æn√© et valid√© par une v√©rit√© terrain ne sont pas comparables avec celles d'un mod√®le entra√Æn√© et valid√© par une nouvelle version de la v√©rit√© terrain.

### 4.5. Restitution et visualisation

La visualisation ne fait pas partie de la _data pipeline_ mais est possible gr√¢ce aux r√©sultats stock√©s des √©tapes pr√©c√©dentes. Ces r√©sultats doivent permettre diff√©rents modes de repr√©sentation et de visualisation multi√©chelle pour les publics cibles vari√©s (citoyens, services de la m√©tropole, √©lus). Nous pouvons imaginer des outils sp√©cifiques pour d√©cideurs (vue agr√©g√©e, explicabilit√© des r√©sultats, tra√ßabilit√© des choix et compromis‚Ä¶).

Pour la partie sc√©narisation et outils interactifs du projet, il est possible de stocker une copie sp√©cialis√©e des donn√©es pr√©trait√©es, par exemple, dans un _data mart_ (Annexe B, section B.2.2.), qui pourra √™tre modifi√©e √† la vol√©e par le _back-end_ apr√®s une interaction sur les outils de visualisation _front-end_. Cela red√©clenchera l'ex√©cution de la partie analytique de la _data pipeline_ sp√©cifiquement sur ces donn√©es, r√©sultant sur une mise √† jour de l'affichage.

### 4.6. Gouvernance, qualit√© et reproductibilit√©

La _data pipeline_ n‚Äôest pas uniquement un flux technique, mais une cha√Æne de confiance et de responsabilit√©. √Ä chaque √©tape, il est n√©cessaire :
- D'assurer la tra√ßabilit√© des compromis et choix (quelles donn√©es ont √©t√© retenues, quels arbitrages ont √©t√© appliqu√©s‚Ä¶) pour l'explicabilit√© et la reproductibilit√©.
- De pr√©voir des politiques d‚Äôerreur et d‚Äôalternatives document√©es (que faire en cas de donn√©es manquantes ou incoh√©rentes‚Ä¶).
- De faire de la validation continue de la qualit√© et de la fiabilit√© (g√©om√©trique, statistique, topologique‚Ä¶) via des m√©canismes de contr√¥le.
- De faire de la surveillance (_monitoring_) des performances pour d√©tecter les erreurs, les biais dans les mod√®les, une augmentation de la latence‚Ä¶ La latence faible, l'efficacit√© sont n√©cessaires pour l'outil d'aide √† la d√©cision. Cela pose la question de la faisabilit√© : comment v√©rifier la qualit√© d'une v√©rit√© terrain ? D'un mod√®le ?

## 5. R√©f√©rences

[1] S. Biswas, M. Wardat, and H. Rajan, ‚ÄúThe art and practice of data science pipelines,‚Äù _Proceedings of the 44th International Conference on Software Engineering_, pp. 2091‚Äì2103, May 2022, doi: 10.1145/3510003.3510057. Available: [https://doi.org/10.1145/3510003.3510057](https://doi.org/10.1145/3510003.3510057)

[2] A. Raj, J. Bosch, H. H. Olsson, and T. J. Wang, ‚ÄúModelling Data Pipelines,‚Äù _46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)_, pp. 13‚Äì20, Aug. 2020, doi: 10.1109/seaa51224.2020.00014. Available: [https://doi.org/10.1109/seaa51224.2020.00014](https://doi.org/10.1109/seaa51224.2020.00014)

[3] D. Sculley _et al._, ‚ÄúHidden technical debt in Machine learning systems,‚Äù _Neural Information Processing Systems_, vol. 28, pp. 2503‚Äì2511, Dec. 2015, Available: https://papers.nips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf

[4] A. Lima, L. Monteiro, and A. Furtado, ‚ÄúMLOps: Practices, Maturity Models, Roles, Tools, and Challenges ‚Äì A Systematic Literature Review,‚Äù _24th International Conference on Enterprise Information Systems (ICEIS 2022)_, Jan. 2022, doi: 10.5220/0010997300003179. Available: [https://doi.org/10.5220/0010997300003179](https://doi.org/10.5220/0010997300003179)

[5] D. Sculley _et al._, ‚ÄúMachine Learning: The High Interest Credit Card of Technical Debt,‚Äù _NIPS 2014 Workshop_, Jan. 2014, Available: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43146.pdf

[6] A. P. Wo≈∫niak, M. Milczarek, and J. Wo≈∫niak, ‚ÄúMLOPs Components, Tools, Process and Metrics - A Systematic Literature review,‚Äù _IEEE Access_, p. 1, Jan. 2025, doi: 10.1109/access.2025.3534990. Available: [https://doi.org/10.1109/access.2025.3534990](https://doi.org/10.1109/access.2025.3534990)

[7] A. Serban, K. Van Der Blom, H. Hoos, and J. Visser, ‚ÄúAdoption and Effects of Software Engineering Best Practices in Machine Learning,‚Äù _Proceedings of the 14th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)_, pp. 1‚Äì12, Oct. 2020, doi: 10.1145/3382494.3410681. Available: [https://doi.org/10.1145/3382494.3410681](https://doi.org/10.1145/3382494.3410681)

[8] Wikipedia contributors, ‚ÄúOnline transaction processing,‚Äù _Wikipedia_, Apr. 28, 2025. Available: https://en.wikipedia.org/wiki/Online_transaction_processing

[9] Wikipedia contributors, ‚ÄúOnline analytical processing,‚Äù _Wikipedia_, Jun. 06, 2025. Available: https://en.wikipedia.org/wiki/Online_analytical_processing

[10] Wikipedia contributors, ‚ÄúData warehouse,‚Äù _Wikipedia_, May 24, 2025. Available: https://en.wikipedia.org/wiki/Data_warehouse

[11] Wikipedia contributors, ‚ÄúData mart,‚Äù _Wikipedia_, Dec. 22, 2024. Available: https://en.wikipedia.org/wiki/Data_mart

[12] Wikipedia contributors, ‚ÄúData lake,‚Äù _Wikipedia_, Mar. 14, 2025. Available: https://en.wikipedia.org/wiki/Data_lake

[13] ‚ÄúWhat is a Data Lakehouse? | Databricks,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/data-lakehouse

[14] Wikipedia contributors, ‚ÄúLambda architecture,‚Äù _Wikipedia_, Feb. 11, 2025. Available: https://en.wikipedia.org/wiki/Lambda_architecture

[15] ‚ÄúData Pipelines: All the answers you need | DataBricks,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/data-pipelines

[16] ‚ÄúData Warehouse | DataBricks,‚Äù _Databricks_. Available: https://www.databricks.com/discover/data-warehouse

[17] ‚ÄúExtract Transform Load (ETL) | DataBricks,‚Äù _Databricks_. Available: https://www.databricks.com/discover/etl

[18] ‚ÄúLambda Architecture Basics | DataBricks,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/lambda-architecture

[19] ‚ÄúWhat is a Medallion Architecture?,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/medallion-architecture

[20] ‚ÄúWhat is a Data Mart? Definition | Databricks,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/data-mart

[21] ‚ÄúACID Transactions in Databases | DataBricks,‚Äù _Databricks_. Available: https://www.databricks.com/glossary/acid-transactions

[22] ‚ÄúMl-ops.org,‚Äù Mar. 24, 2025. Available: https://ml-ops.org/

[23] ‚ÄúKappa Architecture - Data Engineering Wiki.‚Äù Available: https://dataengineering.wiki/Concepts/Data+Architecture/Kappa+Architecture

[24] ‚ÄúAbout Copernicus | Copernicus.‚Äù Available: https://www.copernicus.eu/en/about-copernicus

[25] Wikipedia contributors, ‚ÄúExtract, transform, load,‚Äù _Wikipedia_, Jun. 04, 2025. Available: https://en.wikipedia.org/wiki/Extract,_transform,_load

[26] Wikipedia contributors, ‚ÄúExtract, load, transform,‚Äù _Wikipedia_, May 06, 2025. Available: https://en.wikipedia.org/wiki/Extract,_load,_transform

[27] ‚ÄúHow lakehouses solve common issues with data warehouses,‚Äù _Databricks_, Feb. 04, 2021. Available: https://www.databricks.com/blog/2021/02/04/how-data-lakehouses-solve-common-issues-with-data-warehouses.html

[28] ‚ÄúDags ‚Äî Airflow 3.1.0 documentation.‚Äù https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#dags

[29] ‚ÄúHome,‚Äù Apache Airflow. https://airflow.apache.org/

[30] V. Arora, ‚ÄúExploring real-world challenges in MLOps implementation: a case study approach to design effective data pipelines,‚Äù M.S. thesis, Inst. Soft. Eng., Univ. Stuttgart, Stuttgart, Germany, 2024.

[31] K. Shivashankar and A. Martini, ‚ÄúMaintainability Challenges in ML: A Systematic Literature Review,‚Äù 2022 48th Euromicro Conference on Software Engineering and Advanced Applications (SEAA), Gran Canaria, Spain, 2022, pp. 60-67, doi: 10.1109/SEAA56994.2022.00018

[32] Z. S. Rad and M. Ghobaei-Arani, ‚ÄúData pipeline approaches in serverless computing: a taxonomy, review, and research trends,‚Äù Journal of Big Data, vol. 11, no. 1, Jun. 2024, doi: 10.1186/s40537-024-00939-0.

[33] A. R. Munappy, J. Bosch, and H. H. Olsson, ‚ÄúData Pipeline Management in Practice: Challenges and opportunities,‚Äù in Lecture notes in computer science, 2020, pp. 168‚Äì184. doi: 10.1007/978-3-030-64148-1_11.

[34] C. K. Dehury, P. Jakovits, S. N. Srirama, G. Giotis, and G. Garg, ‚ÄúTOSCAdata: Modeling data pipeline applications in TOSCA,‚Äù Journal of Systems and Software, vol. 186, p. 111164, Dec. 2021, doi: 10.1016/j.jss.2021.111164.

[35] H. Foidl, V. Golendukhina, R. Ramler, and M. Felderer, ‚ÄúData pipeline quality: Influencing factors, root causes of data-related issues, and processing problem areas for developers,‚Äù Journal of Systems and Software, vol. 207, p. 111855, Sep. 2023, doi: 10.1016/j.jss.2023.111855.

[36] S. R. Poojara, C. K. Dehury, P. Jakovits, and S. N. Srirama, ‚ÄúServerless data pipeline approaches for IoT data in fog and cloud computing,‚Äù Future Generation Computer Systems, vol. 130, pp. 91‚Äì105, Dec. 2021, doi: 10.1016/j.future.2021.12.012.

[37] M. Matskin, S. Tahmasebi, A. Layegh, A. Payberah, A. Thomas, N. Nikolov, and D. Roman, ‚ÄúA Survey of Big Data Pipeline Orchestration Tools from the Perspective of the DataCloud Project,‚Äù in Suppl. Proc. DAMDID/RCDL, 2021, pp. 63-78.

[38] S. N. Mitchell et al., ‚ÄúFAIR data pipeline: provenance-driven data management for traceable scientific workflows,‚Äù Philosophical Transactions of the Royal Society a Mathematical Physical and Engineering Sciences, vol. 380, no. 2233, Aug. 2022, doi: 10.1098/rsta.2021.0300.

[39] I. Lipovac and M. B. Babac, ‚ÄúDeveloping a data pipeline solution for big data processing,‚Äù International Journal of Data Mining Modelling and Management, vol. 16, no. 1, pp. 1‚Äì22, Jan. 2024, doi: 10.1504/ijdmmm.2024.136221.

[40] S. Stoudt, V. N. V√°squez, and C. C. Martinez, ‚ÄúPrinciples for data analysis workflows,‚Äù PLoS Computational Biology, vol. 17, no. 3, p. e1008770, Mar. 2021, doi: 10.1371/journal.pcbi.1008770.

[41] K. Raman, A. Swaminathan, J. Gehrke, and T. Joachims, ‚ÄúBeyond myopic inference in big data pipelines,‚Äù Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Aug. 2013, doi: 10.1145/2487575.2487588.

[42] S. Agostinelli, D. Benvenuti, F. De Luzi, and A. Marrella, ‚ÄúBig Data Pipeline Discovery through Process Mining: Challenges and Research Directions,‚Äù in CEUR Workshop Proc., 2021, pp. 50-55.

[43] O. Oleghe and K. Salonitis, ‚ÄúA framework for designing data pipelines for manufacturing systems,‚Äù Procedia CIRP, vol. 93, pp. 724‚Äì729, Jan. 2020, doi: 10.1016/j.procir.2020.04.016.

[44] ‚ÄúApache Kafka,‚Äù Apache Kafka. https://kafka.apache.org/

[45] ‚ÄúThe 2024 MAD (ML, AI & Data) Landscape,‚Äù FirstMark. https://mad.firstmark.com/

[46] ‚ÄúProduction-Grade Container orchestration,‚Äù Kubernetes. https://kubernetes.io/

[47] ‚ÄúApache Flink¬Æ ‚Äî Stateful Computations over Data Streams,‚Äù Apache Flink. https://flink.apache.org/

[48] Wikipedia contributors, ‚ÄúChange data capture,‚Äù Wikipedia, Aug. 15, 2025. https://en.wikipedia.org/wiki/Change_data_capture

[49] ‚ÄúThe Snowflake platform,‚Äù Snowflake. https://www.snowflake.com/en/product/platform/

[50] ‚ÄúD‚Äôun entrep√¥t de donn√©es √† une plate-forme de donn√©es et d‚ÄôIA autonome,‚Äù Google BigQuery. https://cloud.google.com/bigquery?hl=fr

[51] ‚ÄúAmazon S3 ‚Äì Stockage d‚Äôobjets dans le cloud ‚Äì AWS,‚Äù Amazon Web Services, Inc. https://aws.amazon.com/fr/s3/

[52] ‚ÄúApache Hudi | An open source Data Lake platform | Apache Hudi.‚Äù https://hudi.apache.org/

[53] ‚ÄúHome | Delta Lake,‚Äù Delta Lake. https://delta.io/

[54] ‚ÄúApache Iceberg - Apache IcebergTM.‚Äù https://iceberg.apache.org/

[55] ‚ÄúApache SparkTM - Unified Engine for large-scale data analytics.‚Äù https://spark.apache.org/

[56] ‚ÄúAccelerate data workflows with the dbt Fusion engine | dbt Labs,‚Äù Dbt Labs. https://www.getdbt.com/product/fusion

[57] ‚ÄúDistributed SQL query engine for big data.‚Äù https://trino.io/

[58] ‚ÄúPythonic, modern workflow orchestration for resilient data platforms | Prefect.‚Äù https://www.prefect.io/

[59] Dagster, ‚ÄúModern Data Orchestrator Platform | Dagster,‚Äù Dagster. https://dagster.io/

[60] S. Ratliff, ‚ÄúDocker: Accelerated Container Application Development,‚Äù Docker, Aug. 25, 2025. https://www.docker.com/

[61] ‚ÄúTerraform,‚Äù HashiCorp Cloud Platform. https://developer.hashicorp.com/terraform

[62] ‚ÄúHelm | Helm.‚Äù https://helm.sh/

[63] A. Community, ‚ÄúAnsible documentation.‚Äù https://docs.ansible.com/

[64] ‚ÄúAI & Data Production | Data Governance Compliance,‚Äù Datahub. https://datahub.com/products/data-governance/

[65] ‚ÄúAmundsen, the leading open source data catalog.‚Äù https://www.amundsen.io/

[66] ‚ÄúCollibra Data Governance software | Data Governance tool | Collibra,‚Äù Collibra. https://www.collibra.com/products/data-governance

[67] ‚ÄúGreat Expectations: have confidence in your data, no matter what.‚Äù https://greatexpectations.io/

[68] ‚ÄúSoda Data quality.‚Äù https://www.soda.io/

[69] ‚ÄúTableau,‚Äù Tableau From Salesforce. https://www.tableau.com/fr-fr/products/tableau

[70] ‚ÄúPower BI ‚Äì Visualisation des donn√©es | Microsoft Power Platform.‚Äù https://www.microsoft.com/fr-fr/power-platform/products/power-bi

[71] ‚ÄúGraphQL | A query language for your API.‚Äù https://graphql.org/

[72] ‚ÄúProject Jupyter,‚Äù Home. https://jupyter.org/

[73] ‚ÄúAFNOR SPEC 2314,‚Äù Afnor EDITIONS. https://www.boutique.afnor.org/fr-fr/norme/afnor-spec-2314/referentiel-general-pour-lia-frugale-mesurer-et-reduire-limpact-environneme/fa208976/421140

[74] ‚Äúüåø iPAV√â : du vert dans les donn√©es !,‚Äù IA.rbre. https://iarbre.fr/actualites/-ipav%C3%A9-du-vert-dans-les-donn%C3%A9es/

[75] ‚ÄúD√©claration de travaux √† proximit√© de r√©seaux (DT-DICT),‚Äù Entreprendre.Service-Public.fr, Apr. 09, 2025. https://entreprendre.service-public.gouv.fr/vosdroits/F23491?profil=tout

[76] ‚ÄúTCL - Transports en commun,‚Äù TCL - Transports En Commun. https://www.tcl.fr/

[77] M. Al-Mekhlal and A. Ali Khwaja, ‚ÄúA Synthesis of Big Data Definition and Characteristics,‚Äù 2019 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC), New York, NY, USA, 2019, pp. 314-322, doi: 10.1109/CSE/EUC.2019.00067.

[78] Ibm, ‚ÄúData mesh,‚Äù IBM, May 28, 2025. https://www.ibm.com/fr-fr/think/topics/data-mesh

[79] A. Jonker and T. Krantz, ‚ÄúData fabric,‚Äù IBM, Aug. 22, 2025. https://www.ibm.com/fr-fr/think/topics/data-fabric

---

## Annexe A. Fondations des cha√Ænes de traitement de donn√©es

- A.1. Notions de base
  - A.1.1. √âtapes
  - A.1.2. Propri√©t√©s
  - A.1.3. Formats et sources des donn√©es, destinations des r√©sultats
  - A.1.4. Modes de d√©clenchement, d'ingestion, d'ex√©cution
- A.2. R√¥les et objectifs
- A.3. Diff√©rences avec _data workflow_
- A.4. Repr√©sentation
- A.5. Architectures
  - A.5.1. Architecture g√©n√©rale
  - A.5.2. Architectures sp√©cifiques
    - A.5.2.1. _Machine learning_
    - A.5.2.2. ETL (_Extract-Transform-Load_)
    - A.5.2.3. ELT (_Extract-Load-Transform_)
    - A.5.2.4. Architecture Lambda
      - A.5.2.4.1. Objectifs
      - A.5.2.4.2. Limites
    - A.5.2.5. Architecture Kappa
      - A.5.2.5.1. Objectifs
      - A.5.2.5.2. Limites
    - A.5.2.6. Architecture m√©daillon
      - A.5.2.6.1. Objectifs
      - A.5.2.6.2. Limites
    - A.5.2.7. Architecture 2-tiers (_data lake_ et _data warehouse_)
      - A.5.2.7.1. Objectifs
      - A.5.2.7.2. Limites
- A.6. Infrastructures
- A.7. Op√©rationnalisation
- A.8. Impl√©mentation moderne
- A.9. Meilleures pratiques
  - A.9.1. Architecture g√©n√©rale
  - A.9.2. Infrastructure
- A.10. Comp√©tences requises

La litt√©rature scientifique regorge d'utilisations du terme ¬´ _data pipeline_ ¬ª. Le concept est encore √† un stade pr√©coce de d√©veloppement et ne b√©n√©ficie pas d'une standardisation et d'une terminologie largement accept√©e [1].

Cette annexe investigue la probl√©matique : qu'est-ce qu'une cha√Æne de traitement de donn√©es, selon la litt√©rature scientifique, d'un point de vue conceptuel et pratique ?

Elle fournit une vue d‚Äôensemble des fondations, en couvrant leurs notions de base, r√¥les et objectifs, diff√©rences avec _data workflow_, repr√©sentation, architectures et infrastructures, op√©rationnalisation, impl√©mentation moderne, meilleures pratiques et comp√©tences techniques associ√©es.

### A.1. Notions de base

Le terme _data pipeline_ d√©signe g√©n√©ralement une structure logicielle qui permet le d√©placement et la manipulation syst√©matiques de donn√©es provenant de sources potentiellement multiples [31, 32, 35] et h√©t√©rog√®nes, vers des destinations (stockages ou autres) [2, 30, 31, 32, 33, 35, 39, 40].

Les d√©finitions varient quant au niveau d'abstraction : certaines la d√©crivent comme une partie de logiciel [33], un service unique [36], un graphe orient√© acyclique (DAG) [35], tandis que d'autres √©tendent le concept et la d√©crivent comme un syst√®me logiciel complet avec un √©cosyst√®me comprenant plusieurs technologies et outils interconnect√©s [35, 43].

Un consensus g√©n√©ral se d√©gage quant au fait qu‚Äôune _data pipeline_ se compose d‚Äôune s√©rie [2, 30, 32, 40] (cha√Æne [2, 33, 41, 42], s√©quence [31, 32, 34, 35], ensemble [36, 39]) d'√©tapes [32] (processus [30, 32, 33, 36, 39, 40, 41], fonctions [32], op√©rations [2, 31], outils [39], n≈ìuds [33, 35], √©l√©ments de traitement [42], blocs de _data pipeline_ [34], activit√©s [2]) interconnect√©es √† travers lesquelles les donn√©es passent de mani√®re s√©quentielle, la sortie d'une √©tape servant d'entr√©e pour la suivante [2, 32, 34, 35, 36, 41, 42].

#### A.1.1. √âtapes

Les √©tapes consistent en un ensemble de traitements sp√©cifiques appliqu√©s aux donn√©es, allant de l'extraction, la transformation et le chargement (ETL), au filtrage, √† la fusion ou √† d‚Äôautres formes de manipulation [2, 31, 32, 33, 34, 35, 36, 39, 42]. Voici quelques √©tapes fr√©quemment mentionn√©es : s√©lection, ingestion, acquisition, extraction, exploration, chargement, traitement, agr√©gation, gestion, transformation, validation, fusion, filtrage, enrichissement, stockage, analyse, visualisation.

Des divergences apparaissent quant au nombre, √† la terminologie et √† l'organisation des √©tapes. Certains travaux adoptent une vision simplifi√©e, d√©finissant quatre √©tapes principales (acquisition, int√©gration, analyse et application concr√®te) [39], tandis que d'autres mettent l'accent sur les 3 √©tapes de l'architecture ETL (extraction, transformation et chargement) [34]. Dans les contextes impliquant l'apprentissage automatique, il peut y avoir des √©tapes sp√©cifiques comme la pr√©paration des ¬´ _features_ ¬ª et le d√©veloppement de mod√®les avec l'entra√Ænement et l'√©valuation [30].

Dans [1], les auteurs s'appuient sur l‚Äôanalyse de _data pipelines_ issues de la litt√©rature scientifique, de la plateforme _Kaggle_, ainsi que de projets de _data science_ d‚Äôenvergure publi√©s sur _GitHub_ (_Autopilot_, _CNN-Text-Classification_, _Darkflow_, _Deep ANPR_‚Ä¶) afin de conduire une √©tude empirique visant, entre autres, √† unifier leurs √©tapes et t√¢ches. L'√©tude s'int√©resse plus particuli√®rement aux _data pipelines_ de science des donn√©es comme une extension des _data pipelines_ classiques, int√©grant des √©tapes propres √† l‚Äôanalyse, √† l‚Äôentra√Ænement, √† l‚Äô√©valuation et au d√©ploiement des mod√®les.

Le Tableau 1 pr√©sente le r√©sultat de cette unification avec le nom des √©tapes retenues et une description pour chacune. Les √©tapes sont organis√©es dans l'ordre de l'architecture que nous pr√©sentons dans la section A.5.1., de l'acquisition de donn√©es, au d√©ploiement de la solution, en passant par la pr√©paration des donn√©es, la mod√©lisation, l'entra√Ænement, l'√©valuation ou encore la pr√©diction.

![Tableau 1. Description des √©tapes dans une _data pipeline_ de science des donn√©es selon [1].](images/description-of-the-stages-in-ds-pipeline-s-biswas-m-wardat-h-rajan.png)

**Tableau 1. Description des √©tapes dans une _data pipeline_ de science des donn√©es selon [1].**

Certains auteurs notent que les √©tapes peuvent poss√©der plusieurs capacit√©s, ex√©cuter plusieurs t√¢ches de traitement [1, 41].

Les √©tapes d'extraction, acquisition, peuvent porter sur toutes les donn√©es d'origine ou une partie, par exemple les donn√©es actualis√©es ; et il est imaginable de les remplacer par des √©tapes de g√©n√©ration de donn√©es.

La pr√©paration des donn√©es, autrement appel√©e transformation des donn√©es, est une √©tape qui permet de r√©concilier les divergences et de garantir que celles-ci se trouvent dans un format adapt√© pour le traitement suivant, tout en garantissant leur qualit√©. Elle inclut en fonction des besoins les t√¢ches de purge, v√©rification de l'int√©grit√©, agr√©gation, fusion, encodage, synchronisation, changement de format et standardisation, normalisation, nettoyage, filtrage, enrichissement, √©chantillonnage, r√©duction des dimensions, validation (s'assurer de la qualit√© notamment que les donn√©es sont compl√®tes et justes). Les donn√©es transform√©es peuvent √™tre plac√©es dans un stockage temporaire afin de permettre un retour en arri√®re rapide en cas de probl√®me.

#### A.1.2. Propri√©t√©s

Certaines d√©finitions pr√©cisent que les _data pipelines_ doivent pr√©senter des propri√©t√©s telles que la modularit√©, la capacit√© de d√©ploiement ind√©pendant, la scalabilit√© et la portabilit√© dans les environnements _Cloud_, ce qui se manifeste √† la conception et √† l'impl√©mentation des diff√©rentes √©tapes [34].

De m√™me, certaines d√©finitions d√©crivent les _data pipelines_ comme enti√®rement automatis√©es [30] avec des √©tapes pouvant √™tre impl√©ment√©es par programmation [40], tandis que d'autres consid√®rent l'automatisation comme un objectif de conception plut√¥t que comme une condition absolue, visant √† r√©duire, mais pas n√©cessairement √† √©liminer, l'intervention humaine √† chaque √©tape [33].

#### A.1.3. Formats et sources des donn√©es, destinations des r√©sultats

Les _data pipelines_ sont con√ßues pour traiter des donn√©es dans des formats vari√©s (non structur√©s, semi-structur√©s, structur√©s) et provenant de sources h√©t√©rog√®nes, locales ou distantes, centralis√©es ou distribu√©es (API, fichiers, base de donn√©es, origines d'un _crawling_ ou _scraping_‚Ä¶). De nombreuses impl√©mentations garantissent la compatibilit√© avec pratiquement toutes les sources de donn√©es [30, 33].

La litt√©rature souligne les diff√©rences dans les destinations pr√©vues des r√©sultats des _data pipelines_. Alors que certaines √©tapes aboutissent au stockage, d'autres fournissent des donn√©es √† des applications telles que des outils de visualisation, d'autres _data pipelines_, des mod√®les d'apprentissage automatique ou des mod√®les d'apprentissage profond [2, 33].

#### A.1.4. Modes de d√©clenchement, d'ingestion, d'ex√©cution

Les modes de d√©clenchement des cha√Ænes de traitement de donn√©es varient. L'ex√©cution peut √™tre d√©clench√©e manuellement ou de mani√®re programm√©e, ponctuellement, de mani√®re r√©currente (par exemple, quotidiennement, hebdomadairement), ou en r√©ponse √† des stimuli bas√©s sur des √©v√©nements, tels que l'arriv√©e de nouvelles donn√©es dans un syst√®me de stockage [40].

Les _data pipelines_ prennent en charge diff√©rents modes d'ingestion de donn√©es, notamment le traitement par lots (¬´ _batch_ ¬ª) et continu (¬´ _streaming_ ¬ª) [2, 33, 35, 38]. En mode _batch_, les donn√©es sont ing√©r√©es √† intervalles fixes ou lors de d√©clenchements sp√©cifiques. En revanche, en mode _streaming_, elles consomment et traitent les donn√©es en continu d√®s qu'elles sont disponibles [35, 38]. Il existe certaines approches hybrides, comme les architectures Lambda (section A.5.2.4.), qui int√®grent les deux paradigmes d'ingestion et permettent de traiter simultan√©ment plusieurs flux de donn√©es [33, 35].

Les traitements peuvent √™tre ex√©cut√©s s√©quentiellement ou parall√®lement, et de mani√®re centralis√©e ou distribu√©e.

### A.2. R√¥les et objectifs

Les _data pipelines_ constituent la fondation des activit√©s de traitement, d‚Äôanalyse et de prise de d√©cision [33, 35] gr√¢ce √† leur capacit√© √† g√©rer des flux de donn√©es en quantit√©s toujours croissantes. Par exemple, dans le cadre du _machine learning_, elles permettent de les mettre sous une forme appropri√©e pour l'entra√Ænement des mod√®les [35].

Un second objectif majeur consiste √† r√©duire la latence dans le d√©veloppement des produits de donn√©es [2, 33]. √Ä cet √©gard, ces structures permettent de contr√¥ler toutes les op√©rations li√©es aux donn√©es et d'orchestrer l'ensemble du flux de mani√®re rationalis√©e de la source √† la destination [33, 35]. Elles favorisent leur traitement, leur transfert et leur stockage efficaces et fiables [32, 35], possiblement automatis√©s, √©liminant les erreurs [33]. Par ailleurs, elles contribuent √† att√©nuer les goulots d‚Äô√©tranglement et les d√©lais [33]. Cela augmente la vitesse de bout en bout [2, 33].

Enfin, les _data pipelines_ visent √† simplifier la conception et le d√©ploiement des services de traitement des donn√©es [36]. Dans cette perspective, elles d√©composent les analyses complexes de grands ensembles de donn√©es en une s√©rie de t√¢ches plus simples [33]. Les propri√©t√©s des impl√©mentations des diff√©rentes √©tapes visent √† encourager la r√©utilisation, la composition flexible et la configurabilit√© pour des usages sp√©cifiques [34, 41]. Elles contribuent √©galement √† renforcer la scalabilit√©, car des √©tapes peuvent √™tre ajout√©es ou supprim√©es en fonction de la charge de travail et des exigences de traitement [32].

En compl√©ment de ces objectifs principaux, les _data pipelines_ poursuivent des objectifs secondaires tels que la reproductibilit√© [38], la tra√ßabilit√© et la tol√©rance aux pannes [33].

### A.3. Diff√©rences avec _data workflow_

Tout comme ¬´ _data pipeline_ ¬ª, le concept de ¬´ _data workflow_ ¬ª est encore √† un stade pr√©coce de d√©veloppement et ne b√©n√©ficie pas d'une standardisation et d'une terminologie largement accept√©e.

La litt√©rature pr√©sente diff√©rentes relations entre les termes ¬´ _data workflow_ ¬ª et ¬´ _data pipeline_ ¬ª, souvent d√©pendantes du contexte [40].

Dans certains travaux, les deux termes sont consid√©r√©s comme synonymes [37], par exemple, dans le contexte du d√©veloppement et de l'ing√©nierie logiciels [40].

Dans le contexte du _Big Data_, les _data pipelines_ sont parfois d√©finis comme des cas particuliers des _data workflows_, o√π ces seconds sont davantage orient√©s vers les utilisateurs finaux, sans expliciter cette notion [37].

¬´ _Data workflow_ ¬ª semble souvent d√©signer un concept, dont les limites sont floues, d'ensemble des flux et traitements de la donn√©e englobant la logique m√©tier, le cycle de vie, les m√©canismes d'orchestration pour g√©rer l‚Äôex√©cution de t√¢ches (et leurs d√©pendances) pouvant inclure des √©tapes humaines (comme d'intervention et de prise de d√©cision), le ¬´ _monitoring_ ¬ª, la gestion des erreurs et la validation des donn√©es, la gouvernance, l'op√©rationnalisation. Tandis que ¬´ _data pipeline_ ¬ª d√©signe l'impl√©mentation technique. Par exemple :
- Dans [35], les _data pipelines_ sont d√©crites comme des _data workflows_ num√©ris√©s compos√©s de scripts programm√©s ou d'outils logiciels simples.
- Dans [32], il est dit ¬´ _efficient and reliable data pipelines provides a compelling approach to creating efficient, scalable, and cost-effective data processing workflow_ ¬ª.
- Dans [2], il est dit ¬´ _The conceptual data pipeline model proposed in this paper has nodes and connectors which perform the activities in the data workflow_ ¬ª.

D‚Äôautres sources, toutefois, √©tablissent une distinction plus nette entre les deux notions. Certains auteurs utilisent le terme ¬´ _data pipeline_ ¬ª pour d√©signer principalement ce qu'un ordinateur ex√©cute, comme l'ex√©cution automatis√©e d'une s√©rie de scripts, tandis que le terme ¬´ _data workflow_ ¬ª est utilis√© pour englober l'ensemble plus large des activit√©s humaines et informatiques qu'un chercheur entreprend pour faire avancer l'investigation scientifique, notamment l'√©laboration d'hypoth√®ses, le pr√©traitement des donn√©es, l'√©criture de code et l'interpr√©tation des r√©sultats. Dans cette perspective, les _data workflows_ peuvent produire des r√©sultats diversifi√©s au-del√† des logiciels ou des publications acad√©miques, tels que de nouveaux jeux de donn√©es, des approches m√©thodologiques ou du mat√©riel p√©dagogique [40].

Il existe beaucoup d'autres diff√©rences que nous n'expliciterons pas ici, comme la lin√©arit√© des _data pipelines_ contre la non-lin√©arit√© des _data workflows_ [40].

### A.4. Repr√©sentation

La repr√©sentation classique, le m√©tamod√®le des _data pipelines_, est un diagramme de flux de donn√©es qui peut prendre plusieurs formes dont la plus commune est un graphe orient√© acyclique (_Directed acyclic graph_, DAG) ou g√©n√©ralement, mais plus rarement, un graphe orient√© si des boucles sont autoris√©es.

Le DAG est d'ailleurs la repr√©sentation qui est utilis√©e dans la plupart des outils d'orchestrateur de _data pipelines_ comme _Apache Airflow_ [28].

### A.5. Architectures

#### A.5.1. Architecture g√©n√©rale

Bien qu'il n'existe pas de normalisation des _data pipelines_, certaines √©tudes cherchent √† d√©terminer la structure (√©tapes, organisation, variations‚Ä¶) et les pratiques typiques.

C‚Äôest notamment le cas de [2], qui propose un mod√®le conceptuel de r√©f√©rence (Figure 1) pour une _data pipeline_ de bout en bout, enti√®rement automatis√©e et tol√©rante aux d√©faillances gr√¢ce √† des m√©canismes de _monitoring_ automatique, de d√©tection, d‚Äôatt√©nuation et d‚Äôalerte. Ce mod√®le assure √©galement la tra√ßabilit√© des donn√©es et prend en compte les d√©fis de gestion de donn√©es que les auteurs ont pr√©alablement identifi√©s. Il a √©t√© √©labor√© gr√¢ce √† l'analyse de _data pipelines_ existantes et √† la conduite puis la synth√®se d'entretiens et de r√©unions, ayant pour sujet plusieurs √©tudes de cas d'une grande entreprise de t√©l√©communication, qui ont permis de r√©colter des donn√©es qualitatives. Il a ensuite √©t√© valid√© au moyen d‚Äôentretiens qualitatifs aupr√®s de trois grandes entreprises issues des secteurs des t√©l√©communications, de l‚Äôautomobile et de la fabrication.

Le mod√®le conceptuel est associ√© √† un m√©tamod√®le (Figure 2). Des pr√©cisions telles que le lien entre ces deux √©l√©ments et la description des √©tapes sont disponibles dans le papier initial.

![Figure 1. Mod√®le conceptuel de la _data pipeline_ selon [2].](images/conceptual-model-of-data-pipeline-a-raj-j-bosch-h-h-olsson-t-j-wang.svg)

**Figure 1. Mod√®le conceptuel de la _data pipeline_ selon [2].**

![Figure 2. M√©tamod√®le pour la construction d'une _data pipeline_ selon [2].](images/meta-model-for-building-data-pipeline-a-raj-j-bosch-h-h-olsson-t-j-wang.svg)

**Figure 2. M√©tamod√®le pour la construction d'une _data pipeline_ selon [2].**

C'est aussi un autre des objectifs de [1] que nous avons pr√©sent√©e pr√©c√©demment. En effet, en plus d'unifier les √©tapes et t√¢ches, les auteurs proposent 3 architectures repr√©sentatives des exemples respectivement issus de la litt√©rature scientifique (Figure 3), de la plateforme _Kaggle_ et de projets de _data science_ d‚Äôenvergure publi√©s sur _GitHub_ (Figure 4).

Il est suppos√© que le processus de cr√©ation de _data pipelines_ est souvent ad hoc.

La Figure 3 pr√©sente 11 √©tapes s√©par√©es en 3 couches. Les sous-t√¢ches sont √©num√©r√©es sous chaque √©tape. Les √©tapes sont reli√©es par des boucles de r√©troaction indiqu√©es par des fl√®ches. Les fl√®ches pleines sont toujours pr√©sentes dans le cycle de vie, tandis que les fl√®ches en pointill√© sont facultatives. Des boucles de r√©troaction √©loign√©es (par exemple, du d√©ploiement √† l'acquisition de donn√©es) sont √©galement possibles par le biais d'√©tapes interm√©diaires.

![Figure 3. Architecture de _data pipeline_ de science des donn√©es repr√©sentative de la litt√©rature scientifique selon [1].](images/concepts-in-a-data-science-pipeline-s-biswas-m-wardat-h-rajan.png)

**Figure 3. Architecture de _data pipeline_ de science des donn√©es repr√©sentative de la litt√©rature scientifique selon [1].**

#### A.5.2. Architectures sp√©cifiques

##### A.5.2.1. _Machine learning_

![Figure 4. Architecture de _data pipeline_ de science des donn√©es repr√©sentative des projets d'envergure selon [1].](images/ds-pipeline-in-the-large-s-biswas-m-wardat-h-rajan.png)

**Figure 4. Architecture de _data pipeline_ de science des donn√©es repr√©sentative des projets d'envergure selon [1].**

[1] qualifie les ¬´ projets d'envergure ¬ª comme des projets qui tentent de r√©soudre des probl√®mes g√©n√©raux potentiellement li√©s √† plusieurs jeux de donn√©es.

L'architecture de la _data pipeline_ (Figure 4) pr√©sente deux phases : une phase de d√©veloppement et une phase post-d√©veloppement. La phase de d√©veloppement (en haut en rose) se d√©roule pendant la construction du mod√®le et la phase de post-d√©veloppement (en bas en orange) se d√©roule pour faire des pr√©dictions. Des pr√©cisions sur le fonctionnement complet sont disponibles dans le papier initial.

##### A.5.2.2. ETL (_Extract-Transform-Load_)

D√©signe les _data pipelines_ comportant les processus d‚Äôextraction de donn√©es √† partir d‚Äôune ou plusieurs sources, de leur transformation dans un format exploitable, puis de leur chargement dans un ou plusieurs environnements de destination (tels qu‚Äôune base de donn√©es ou directement √† l'entr√©e du traitement ult√©rieur) afin de permettre leur exploitation [17, 25]. Elles peuvent √™tre une sous-partie d'une _data pipeline_ plus grande, majoritairement au d√©but, mais possiblement ailleurs quand des changements de format sont n√©cessaires.

Cela correspond partiellement √† la partie ¬´ _Pre-processing Layer_ ¬ª dans le mod√®le de [1].

##### A.5.2.3. ELT (_Extract-Load-Transform_)

D√©signe des _data pipelines_ similaires aux ETL √† la diff√©rence que les √©tapes de transformation et de chargement sont invers√©es, de sorte que les donn√©es sont stock√©es dans un format brut avant transformation, ce qui am√©liore la vitesse d'extraction [26]. Le terme ingestion de donn√©es est souvent utilis√© pour caract√©riser une extraction et un chargement sans transformation pr√©alable.

##### A.5.2.4. Architecture Lambda

L‚Äôarchitecture Lambda est con√ßue pour traiter √† la fois des donn√©es historiques (_batch_) et des donn√©es en temps r√©el (_streaming_) au sein d‚Äôune m√™me infrastructure reposant sur deux couches parall√®les.

###### A.5.2.4.1. Objectifs

L‚Äôapproche Lambda vise √† allier pr√©cision (fournie par le traitement _batch_) et rapidit√© (permise par le traitement en temps r√©el), afin de proposer des syst√®mes r√©actifs tout en maintenant un haut niveau de fiabilit√© analytique.

###### A.5.2.4.2. Limites

L‚Äôarchitecture Lambda est souvent critiqu√©e pour sa complexit√© op√©rationnelle, notamment parce qu‚Äôelle exige de maintenir deux chemins de traitement distincts, souvent redondants, ce qui rend le d√©bogage, la maintenance et la synchronisation plus difficiles. Cela a conduit √† l‚Äô√©mergence d‚Äôapproches alternatives comme l‚Äôarchitecture Kappa.

Pour aller plus loin : [14, 18].

##### A.5.2.5. Architecture Kappa

L‚Äôarchitecture Kappa [14, 23] est une √©volution de l‚Äôarchitecture Lambda qui cherche √† simplifier l‚Äôinfrastructure. Elle propose de traiter toutes les donn√©es sous forme de flux, m√™me les historiques, en rejouant les √©v√©nements √† partir d‚Äôun journal d‚Äô√©v√©nements persist√© (comme _Apache Kafka_ [44]). Il n‚Äôy a donc qu‚Äôun seul chemin de traitement (_steam-only_).

###### A.5.2.5.1. Objectifs

Kappa est pens√©e pour les cas o√π le temps r√©el est primordial et o√π la gestion de deux couches parall√®les (comme dans Lambda) est trop co√ªteuse. Elle permet aussi une plus grande uniformit√© de code et facilite le retraitement des donn√©es simplement en rediffusant le flux initial.

###### A.5.2.5.2. Limites

Kappa suppose que tout peut √™tre mod√©lis√© comme un flux d‚Äô√©v√©nements, ce qui n‚Äôest pas toujours adapt√©, notamment pour des traitements analytiques complexes sur de tr√®s gros volumes historiques. Le mod√®le reste donc plus appropri√© dans des cas d‚Äôusage sp√©cifiques, comme la d√©tection d‚Äô√©v√©nements ou les syst√®mes de recommandation en temps r√©el.

Pour aller plus loin : [14, 23].

##### A.5.2.6. Architecture m√©daillon

L'architecture m√©daillon (Figure 5) pour les _data pipelines_ consiste en une succession d'√©tapes de stockage et de transformation [19].

![Figure 5. Architecture m√©daillon d'une _data pipeline_ selon [19].](images/medallion-architecture-databricks.svg)

**Figure 5. Architecture m√©daillon d'une _data pipeline_ selon [19].**

Dans un premier temps, les donn√©es sont ing√©r√©es, sans traitement, avec des informations d'historique et de tra√ßabilit√©. Ensuite, des transformations simples sont appliqu√©es comme le nettoyage, la d√©duplication, l‚Äôharmonisation des formats, la validation des sch√©mas et parfois des jointures pour obtenir une vue consolid√©e et fiable des donn√©es, mais sans logique m√©tier avanc√©e. Enfin, les donn√©es des transformations avanc√©es, souvent sp√©cifiques au m√©tier, sont appliqu√©es comme des agr√©gations, des enrichissements, des calculs complexes, des mod√©lisations dimensionnelles, pour produire des jeux de donn√©es directement exploitables.

###### A.5.2.6.1. Objectifs

L'architecture m√©daillon est apparue dans la litt√©rature grise en r√©ponse √† un besoin op√©rationnel li√© aux d√©fis du _Big data_ et suite √† une formalisation progressive par la communaut√© des _data engineers_. L'objectif est d'am√©liorer successivement la qualit√© et la structure des donn√©es jusqu'√† les rendre exploitables pour des traitements finaux qui requi√®rent une grande qualit√© comme l'analyse (par exemple, les mod√®les de _machine learning_), le _reporting_‚Ä¶ Cette architecture favorise √©galement la tra√ßabilit√©, la s√©curit√© et la gouvernance.

###### A.5.2.6.2. Limites

Cette architecture implique la conservation de toutes les donn√©es, y compris leurs formes interm√©diaires, ce qui peut entra√Æner une consommation importante d‚Äôespace de stockage et poser des enjeux de s√©curit√©.

##### A.5.2.7. Architecture 2-tiers (_data lake_ et _data warehouse_)

L'architecture 2-tiers [27] d√©signe une _data pipeline_ compos√©e d'une √©tape d'ingestion de donn√©es dans un _data lake_ (Annexe B, section B.2.3.), suivi d'un ETL dont la destination est un _data warehouse_ (Annexe B, section B.2.1.).

###### A.5.2.7.1. Objectifs

L'objectif est de tenter de combiner les avantages du _data lake_ (Annexe B, section B.2.3.) et du _data warehouse_ (Annexe B, section B.2.1.).

###### A.5.2.7.2. Limites

La mise en place d'un tel syst√®me est tout autant difficile que sa maintenance, en ajoutant des √©l√©ments additionnels d'infrastructure, des co√ªts associ√©s de mise en place et d'exploitation et de nouveaux d√©fis de s√©curit√©. Cela cr√©e une duplication des donn√©es et des difficult√©s √† garder les donn√©es actualis√©es dans le _data warehouse_ (Annexe B, section B.2.1.).

### A.6. Infrastructures

L‚Äô√©cosyst√®me autour de la donn√©e conna√Æt aujourd‚Äôhui un essor sans pr√©c√©dent, port√© par l‚Äôexplosion des volumes de donn√©es, la diversification des usages et l‚Äôarriv√©e continue de nouveaux acteurs et de solutions technologiques. Cet univers dynamique regroupe une multitude d‚Äôacteurs : fournisseurs de donn√©es, plateformes, int√©grateurs, sp√©cialistes de la gouvernance, experts en intelligence artificielle, startups innovantes et grandes entreprises, chacun apportant ses propres outils, services et expertises. Face √† cette richesse et cette complexit√©, il serait impossible de d√©tailler ici l‚Äôensemble des solutions existantes, tant le paysage √©volue rapidement et s‚Äôenrichit chaque ann√©e de nouvelles ressources. Pour en donner une id√©e concr√®te et illustrer la diversit√© ainsi que la vitalit√© de cet √©cosyst√®me en pleine expansion, M. Turck (FirstMark) propose un aper√ßu visuel non exhaustif [45].

### A.7. Op√©rationnalisation

La mise en production des traitements et mod√®les de _machine learning_ et d'intelligence artificielle, l'op√©rationnalisation des cha√Ænes de traitement de donn√©es, soul√®vent des probl√®mes sp√©cifiques non pr√©sents dans le cycle de vie du d√©veloppement logiciel traditionnel. Le d√©veloppement de logiciels traditionnels repose sur un ensemble d'exigences bien d√©finies (d√©terministe), tandis que les solutions de _machine learning_ sont bas√©es sur l'exp√©rimentation avec un ensemble de donn√©es, des biblioth√®ques et des param√®tres constamment nouveaux afin d'am√©liorer la pr√©cision du mod√®le (probabiliste), ce qui rend l'op√©rationnalisation plus difficile [4].

Cette sp√©cificit√© a vu la naissance r√©cente de disciplines comme _DataOps_, _MLOps_, _AIOps_ comme adaptation du _DevOps_, avec pour but de r√©duire le cycle de vie entre le d√©veloppement et l'op√©rationnalisation gr√¢ce √† l'int√©gration et le d√©ploiement continu, et fond√© sur des pratiques, des principes, des environnements, des outils. Parmi ces pratiques, sont √©tudi√©s l'impl√©mentation et le d√©veloppement, la maintenance, le versionnement, le _monitoring_ de l'efficacit√© et de la fiabilit√© pour √©viter la d√©gradation dans le temps, le test des mod√®les‚Ä¶

Pour en savoir plus sur les disciplines et les objectifs, les principes, les pratiques, les outils, les m√©triques et autres : [4, 6, 7, 22].

### A.8. Impl√©mentation moderne

La gestion moderne des donn√©es repose sur une architecture complexe et modulaire, con√ßue pour r√©pondre aux exigences croissantes de volume, de diversit√© et de vitesse d‚Äôanalyse des donn√©es. L‚Äôapproche actuelle se structure autour d‚Äôune _data stack_, combinant plusieurs couches logiques, interconnect√©es par des _data pipelines_ robustes, avec une infrastructure capable de s‚Äôadapter tant aux environnements _Cloud_ qu‚Äôaux d√©ploiements hybrides ou _on-premise_, souvent orchestr√©s √† l‚Äôaide de technologies comme _Kubernetes_ [46].

Au c≈ìur de cette architecture se trouve la s√©paration logique des responsabilit√©s en plusieurs couches fonctionnelles : ingestion, transformation, stockage, orchestration, gouvernance et consommation. Chacune de ces couches repose sur des composants sp√©cialis√©s, int√©gr√©s de mani√®re coh√©rente afin d‚Äôassurer la fluidit√©, la fiabilit√© et la tra√ßabilit√© des flux de donn√©es.

Le processus d√©bute par l‚Äôingestion des donn√©es, o√π des outils comme _Apache Kafka_ [44], _Flink_ [47], ou les connecteurs CDC (_Change Data Capture_) [48] collectent les donn√©es depuis diverses sources : bases de donn√©es transactionnelles, API, capteurs IoT, fichiers etc. Ces donn√©es sont g√©n√©ralement normalis√©es et transf√©r√©es en temps r√©el ou en mode _batch_ vers une zone de transit ou de pr√©paration, souvent appel√©e _landing zone_.

La transformation des donn√©es, souvent g√©r√©e dans des _data warehouses_ (Annexe B, section B.2.1.) comme _Snowflake_ [49] et _BigQuery_ [50], _data lakes_ (Annexe B, section B.2.3.) comme _Amazon S3_ [51] et _Apache Hudi_ [52], ou des _data lakehouses_ (Annexe B, section B.2.4.) modernes comme _Delta Lake_ [53] ou _Apache Iceberg_[54] ; implique un traitement qui peut √™tre r√©alis√© par des moteurs comme _Apache Spark_ [55], _dbt_ [56] ou _Trino_ [57]. Ces processus visent √† nettoyer, enrichir et mod√©liser les donn√©es selon des logiques m√©tiers pr√©cises, tout en respectant les principes d‚Äôarchitecture en couches telles que le mod√®le m√©dallion (bronze, argent, or).

Les _data pipelines_, qu‚Äôelles soient _batch_ ou en flux continu, sont orchestr√©es par des outils comme _Apache Airflow_ [29], _Prefect_ [58] ou _Dagster_ [59]. Cette couche permet de d√©finir les d√©pendances, l'ordre, la surveillance et la reprise automatique des t√¢ches. Dans un contexte distribu√© ou hybride, cette orchestration peut √™tre encapsul√©e dans des conteneurs _Docker_ [60], ex√©cut√©s et g√©r√©s par des plateformes comme _Kubernetes_ [46], permettant ainsi une scalabilit√© horizontale et une tol√©rance aux pannes accrue.

L‚Äôinfrastructure sous-jacente repose de plus en plus sur une logique d√©clarative et une automatisation compl√®te du cycle de vie des composants. _Kubernetes_ joue ici un r√¥le central : il offre une couche d‚Äôabstraction sur les ressources mat√©rielles et permet le d√©ploiement coh√©rent de microservices de donn√©es, tout en assurant l‚Äô√©quilibrage de charge, la reprise apr√®s incident et la mise √† l‚Äô√©chelle automatique. L‚Äôinfrastructure est souvent d√©finie par le biais d‚Äôapproches _Infrastructure as Code_ (IaC), utilisant des outils comme _Terraform_ [61], _Helm_ [62] ou _Ansible_ [63].

Un pilier essentiel de la _data stack_ moderne est la gouvernance. Cela comprend le catalogage des donn√©es (avec des outils comme _DataHub_ [64], _Amundsen_ [65] ou _Collibra_ [66]), la tra√ßabilit√© (_data lineage_), la gestion des m√©tadonn√©es, la conformit√© aux r√©glementations (RGPD, HIPAA), ainsi que le contr√¥le d'acc√®s et le chiffrement. La qualit√© des donn√©es est quant √† elle monitor√©e par des _frameworks_ tels que _Great Expectations_ [67] ou _Soda_ [68], int√©gr√©s directement dans les _data pipelines_.

Enfin, la couche de consommation met √† disposition les donn√©es transform√©es pour divers usages analytiques, op√©rationnels ou de science des donn√©es. Les utilisateurs finaux peuvent y acc√©der via des outils de _Business Intelligence_ (_Tableau_ [69], _Power BI_ [70]), des API REST ou _GraphQL_ [71] expos√©es par des _data services_, ou encore via des _notebooks Jupyter_ [72] pour les analystes et les _data scientists_.

### A.9. Meilleures pratiques

#### A.9.1. Architecture g√©n√©rale

Pour garantir l'√©volutivit√©, la flexibilit√© et la robustesse de la _data pipeline_, il faut s'assurer de la concevoir de mani√®re modulaire, de s√©parer, d'isoler clairement les responsabilit√©s au sein des √©tapes, de minimiser les redondances. Une attention particuli√®re doit √™tre port√©e sur l'interface entre les √©tapes. Cette modularit√© apporte de nombreux avantages, notamment en lien avec le contr√¥le de la dette technique [3, 5] : facilitation de la maintenance, de l'entretien et du d√©pannage, meilleure testabilit√©, meilleure s√©curisabilit√©, meilleure reproductibilit√©, meilleure r√©utilisabilit√© [1], facilitation de la documentation‚Ä¶ L'utilisation du m√©tamod√®le peut simplifier la phase de conception.

Il est important de maximiser l'automatisation des √©tapes et t√¢ches pour minimiser l'erreur humaine, la charge de travail et les co√ªts li√©s au volume, la v√©locit√© et la vari√©t√© des donn√©es. Cela contribue √† recentrer l'effort sur des missions √† plus forte valeur ajout√©e que celles de gestion de donn√©es. Une strat√©gie peut √™tre de commencer par l'automatisation des √©tapes, voyant les multiplications du nombre et de la fr√©quence d'interventions humaines.

La _data pipeline_ doit maximiser sa tol√©rance aux d√©faillances avec son recouvrement, qu'elles soient mat√©rielles, algorithmiques ou li√©es √† la qualit√© des donn√©es et aux erreurs m√©tier. √Ä cet effet, il est conseill√© de mettre en place un _monitoring_ (latence, vitesse de transfert, taux d'erreur ; _logs_ d'erreurs, rapports, tableaux de bord‚Ä¶), une d√©tection de d√©faillance, des r√®gles de validation et de r√©jection enti√®re ou partielle, des strat√©gies d'att√©nuation [2], la lev√©e d'alerte et d'√©v√©nements automatiques. Un exemple de cette pratique est la mise en place d'un espace de _staging_ avant validation et stockage des donn√©es pour permettre de revenir en arri√®re en cas d'erreur et de ne pas alt√©rer la qualit√© de la destination pendant l'op√©ration. Un autre exemple peut √™tre le versionnement (donn√©es, _data pipeline_‚Ä¶).

Si les ressources pour le stockage sont suffisantes, il est conseill√© de stocker les donn√©es initiales et les donn√©es interm√©diaires issues de transformation en plus des donn√©es finales pour permettre la reproductibilit√©, la tra√ßabilit√© et laisser la possibilit√© d'appliquer des traitements diff√©rents √† l'avenir, par exemple, pour comparer les performances. Cela √©vite √©galement de refaire l'int√©gralit√© des traitements en cas d'erreur ou de probl√®me de qualit√© interm√©diaire. Il est √©galement conseill√© de s√©parer les stockages initiaux, interm√©diaires et finaux, et de minimiser la duplication qui am√®ne √† des complexit√©s de gestion et une incertitude sur l'√©tat des donn√©es comme l'actualisation.

L'acquisition de donn√©es pouvant √™tre une √©tape critique de la _data pipeline_, il est conseill√© de faire du _data profiling_ pour choisir pr√©cis√©ment les donn√©es √† int√©grer, par exemple, les donn√©es les plus r√©centes par rapport √† celles d√©j√† int√©gr√©es (int√©gration incr√©mentale). L'int√©gration de toutes donn√©es peut amener √† l'explosion des temps d'ex√©cution, de l'espace de stockage pour des donn√©es qui sont potentiellement inutilisables, inutiles. Il est aussi pr√©conis√© de faire un suivi rigoureux de l'origine des donn√©es pour garantir la tra√ßabilit√©.

Il est pr√©f√©rable de choisir une architecture qui privil√©gie une compatibilit√© et une √©volution automatique du sch√©ma pour √™tre flexible √† la vari√©t√© des donn√©es (formats, structures‚Ä¶).

#### A.9.2. Infrastructure

Une bonne pratique est de choisir des outils p√©rennes dans le temps, faciles d'utilisation, faciles √† l'int√©gration, offrant un bon _monitoring_, s√©curis√©s et scalables.

### A.10. Comp√©tences requises

La construction d'une cha√Æne de traitement de donn√©es compl√®te n√©cessite des comp√©tences dans les disciplines √† l'intersection des math√©matiques, de l'informatique et du domaine m√©tier, telles que l'infrastructure, la _data science_, l'ing√©nierie de donn√©es, le _machine learning_, l'algorithmie, l'op√©rationnalisation, la visualisation de donn√©es‚Ä¶

---

## Annexe B. Types de traitement de donn√©es, syst√®mes de stockage et de gestion de donn√©es

- B.1. Types de traitement de donn√©es
  - B.1.1. Traitement transactionnel en ligne (OLTP, _Online Transaction Processing_)
  - B.1.2. Traitement analytique en ligne (OLAP, _Online Analytical Processing_)
  - B.1.3. Autres
- B.2. Syst√®mes de stockage et de gestion de donn√©es
  - B.2.1. _Data warehouse_
    - B.2.1.1. Objectifs
    - B.2.1.2. Limites
  - B.2.2. _Data mart_
    - B.2.2.1. Objectifs
    - B.2.2.2. Limites
    - B.2.2.3. Meilleures pratiques
  - B.2.3. _Data lake_
    - B.2.3.1. Objectifs
    - B.2.3.2. Limites
    - B.2.3.3. Meilleures pratiques
  - B.2.4. _Data lakehouse_
    - B.2.4.1. Objectifs
    - B.2.4.2. Limites
  - B.2.5. Autres

---

Historiquement, les syst√®mes de gestion de bases de donn√©es relationnelles (SGBDR) ont constitu√© le socle des syst√®mes d‚Äôinformation. Ils offrent des garanties √©lev√©es en mati√®re de qualit√©, d‚Äôint√©grit√© r√©f√©rentielle et de coh√©rence transactionnelle (propri√©t√©s ACID [21]). Toutefois, ils pr√©sentent des inconv√©nients face √† la diversit√© et au volume massif des donn√©es caract√©ristiques du _Big data_, comme la difficult√© √† √©voluer horizontalement et le manque de flexibilit√©, notamment √† cause de leur sch√©ma rigide qui n√©cessite de structurer et de normaliser l‚Äôensemble des donn√©es avant leur int√©gration.

Si ces approches demeurent pertinentes pour les besoins transactionnels classiques, l‚Äôessor du _Big data_ a favoris√© l‚Äô√©mergence de nouveaux types de traitement de donn√©es et de nouveaux syst√®mes de stockage et de gestion de donn√©es mieux adapt√©s.

Le type de traitement souhait√©, qu‚Äôil s‚Äôagisse de la rapidit√© d‚Äôex√©cution des transactions (OLTP), de l‚Äôagr√©gation analytique massive (OLAP) ou de la capture en flux continu (OLEP), conditionne fortement le choix du syst√®me de stockage et de gestion de donn√©es et, inversement, les capacit√©s d‚Äôun tel syst√®me influencent les types de traitement envisageables.

La pr√©sente annexe d√©crit les principaux types de traitement de donn√©es et les syst√®mes de stockage et de gestion de donn√©es.

### B.1. Types de traitement de donn√©es

#### B.1.1. Traitement transactionnel en ligne (OLTP, _Online Transaction Processing_)

Type de traitement orient√© vers la gestion de transactions (changement atomique d'√©tat) en temps r√©el, caract√©ris√© par des temps de r√©ponse tr√®s courts, une forte concurrence (nombreuses transactions simultan√©es), une grande disponibilit√© et fiabilit√©, et des requ√™tes g√©n√©ralement simples (insertion, mise √† jour, suppression) [8].

#### B.1.2. Traitement analytique en ligne (OLAP, _Online Analytical Processing_)

Type de traitement con√ßu pour l‚Äôanalyse multidimensionnelle de grandes quantit√©s de donn√©es, permettant d‚Äôex√©cuter rapidement des requ√™tes complexes, souvent agr√©gatives [9].

#### B.1.3. Autres

Il en existe d'autres comme le traitement √©v√©nementiel en ligne (OLEP, _Online Event Processing_) pour la gestion des _logs_ d'√©v√©nements distribu√©s.

### B.2. Syst√®mes de stockage et de gestion de donn√©es

#### B.2.1. _Data warehouse_

Le _data warehouse_ [10, 16] est d√©di√© √† l‚Äôanalyse, en lecture seule pour les utilisateurs, qui agr√®ge et historise des donn√©es issues de multiples sources. Les donn√©es y sont int√©gr√©es r√©guli√®rement, nettoy√©es, transform√©es et organis√©es de mani√®re √† optimiser les analyses d√©cisionnelles et le _reporting_.

Le _data warehouse_ int√®gre √©galement des m√©tadonn√©es (notamment sur la r√©cence des donn√©es) et des processus de gouvernance et de qualit√©.

##### B.2.1.1. Objectifs

Il permet de d√©charger les bases de donn√©es op√©rationnelles, optimis√©es pour la rapidit√© et l‚Äôint√©grit√© transactionnelle (parfois au d√©triment de l‚Äôhistorique), et ayant une structure inefficace pour des requ√™tes d'analyse, vers des bases de donn√©es d√©di√©es et optimis√©es √† cet effet. Cela contribue √† r√©duire les probl√®mes de verrouillage li√©s aux requ√™tes analytiques lourdes et permet d'avoir une ¬´ _single source of truth_ ¬ª car il centralise g√©n√©ralement toutes les donn√©es de mani√®re organis√©e.

##### B.2.1.2. Limites

La normalisation et la transformation des donn√©es peuvent √™tre longues, co√ªteuses et difficiles √† concevoir, surtout si la valeur ajout√©e n‚Äôest pas clairement identifi√©e. De plus, la rigidit√© du sch√©ma peut freiner l‚Äôinnovation et l‚Äôadaptation rapide √† de nouveaux besoins.

#### B.2.2. _Data mart_

Le _data mart_ [11, 20] est un sous-ensemble sp√©cialis√© du _data warehouse_, centr√© sur un domaine m√©tier ou une th√©matique pr√©cise (l√† o√π le _data warehouse_ centralise g√©n√©ralement toutes les donn√©es). Il peut √™tre aliment√© directement √† partir des sources (l'ensemble des _data marts_ forment le _data warehouse_), via un _data warehouse_ central ou une combinaison des deux.

##### B.2.2.1. Objectifs

Les _data marts_ facilitent la performance analytique pour des besoins cibl√©s et favorisent l‚Äôisolation des usages, tout en maintenant une ¬´ _single source of truth_ ¬ª si une gouvernance claire est d√©finie. Leur construction est plus facile qu'un _data warehouse_ complet et n√©cessite moins d'espace de stockage.

##### B.2.2.2. Limites

Les _data marts_, s‚Äôils ne sont pas accompagn√©s d‚Äôune gouvernance rigoureuse, pr√©sentent le risque de cr√©er des silos de donn√©es : chaque domaine m√©tier peut alors d√©velopper ses propres r√©f√©rentiels et d√©finitions, ce qui complique la collaboration, limite la visibilit√© globale et favorise la duplication ou l‚Äôincoh√©rence des informations.

##### B.2.2.3. Meilleures pratiques

Comme pour les _data lakes_, il est essentiel de d√©finir une politique globale claire, des r√®gles de gouvernance de cr√©ation et de gestion des _data marts_ pour √©viter la duplication inutile de donn√©es, un √©tat incoh√©rent des donn√©es, un _data mart_ non align√© sur un besoin m√©tier.

#### B.2.3. _Data lake_

Le _data lake_ [12] permet d‚Äôing√©rer tout type de donn√©es (structur√©es, semi-structur√©es, non structur√©es) dans leur format natif, sans sch√©ma d√©fini √† l'avance (¬´ _schema-on-read_ ¬ª).

L'int√©gration se fait sans aucune pr√©paration des donn√©es donc sans aucune v√©rification de la qualit√© (propret√©, fiabilit√©, compl√©tude, utilit√©‚Ä¶).

##### B.2.3.1. Objectifs

Il r√©pond en partie √† la probl√©matique des silos de donn√©es en favorisant un stockage rapide, peu co√ªteux et √©volutif, adapt√© aux volumes massifs et √† la diversit√© des formats, sans tenir compte des futurs usages, ce qui contribue √† la r√©duction du temps et des co√ªts d‚Äôint√©gration. Il a √©galement pour objectif l'historisation et la facilitation des mises √† jour et du partage des donn√©es.

##### B.2.3.2. Limites

En l‚Äôabsence de gestion et de gouvernance ad√©quates, il existe un risque important de d√©sorganisation, menant √† la formation d‚Äôun ¬´ _data swamp_ ¬ª o√π les donn√©es deviennent difficilement exploitables.

De plus, la maintenance et l‚Äôadministration d‚Äôun _data lake_ s‚Äôav√®rent souvent d√©licates, notamment en raison de la diversit√© et du volume des donn√©es stock√©es. Les enjeux de gouvernance sont √©galement accrus, avec des difficult√©s √† assurer la tra√ßabilit√©, la s√©curit√© et la conformit√© r√©glementaire (par exemple, vis-√†-vis du RGPD). Enfin, l‚Äôabsence de pr√©paration des donn√©es initiales peut g√©n√©rer des temps de pr√©paration suppl√©mentaires dans les traitements utilisant les _data lakes_.

##### B.2.3.3. Meilleures pratiques

Pour √©viter qu'un _data lake_ ne devienne un _data swamp_, il est n√©cessaire de mettre en place des r√®gles de gouvernance claires et rigoureuses, incluant la gestion des m√©tadonn√©es, la qualit√© des donn√©es, la s√©curit√©, ainsi que des processus de catalogage et de tra√ßabilit√© permettant de garantir l'accessibilit√©, la compr√©hension et la fiabilit√©, la conformit√© des donn√©es stock√©es.

#### B.2.4. _Data lakehouse_

Le _data lakehouse_ [12, 13] est une avanc√©e du _data lake_ et du _data warehouse_ combin√©e au sein d'un seul syst√®me. √Ä la mani√®re d'un _data lake_, il permet le stockage rapide, peu co√ªteux et √©volutif de tout type de donn√©es dans leur format natif (en r√©alit√©, le format est semi-natif ouvert), sans sch√©ma d√©fini √† l'avance. Une couche de m√©tadonn√©es est superpos√©e, ce qui permet le support des transactions ACID, des sch√©mas et le versionnement de donn√©es √† la mani√®re d'un _data warehouse_. Les ressources de calcul pour le requ√™tage et l'analyse sont s√©par√©es et optimis√©es, et peuvent √™tre mises √† l'√©chelle ind√©pendamment, ce qui permet d'optimiser les performances et les co√ªts. Les fonctionnalit√©s de gestion de donn√©es et les outils offrent des fonctions de gouvernance (contr√¥le d'acc√®s, tra√ßabilit√©, auditabilit√©) pour garantir la qualit√© et la conformit√© des donn√©es.

##### B.2.4.1. Objectifs

R√©duire les inconv√©nients des _data lakes_, des _data warehouses_ et de l'architecture 2-tiers (Annexe A, section A.5.2.7.).

##### B.2.4.2. Limites

La performance d'un _data lakehouse_ reste l√©g√®rement inf√©rieure √† celle d'un _data warehouse_ et son int√©gration √† des syst√®mes existants est complexe au m√™me titre que la gouvernance.

#### B.2.5. Autres

Il existe d'autres concepts comme _Data mesh_ [78] ou _Data fabric_ [79].
